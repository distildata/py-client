{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build an Experiment with Python API\n",
    "\n",
    "ref: http://docs.h2o.ai/driverless-ai/1-8-lts/docs/userguide/python_client.html\n",
    "\n",
    "nb This is the legacy py client\n",
    "\n",
    "## Sign In\n",
    "Import the required modules and log in.\n",
    "\n",
    "Pass in your credentials through the Client class which creates an authentication token to send to the Driverless AI Server. In plain English: to sign into the Driverless AI web page (which then sends requests to the Driverless Server), instantiate the Client class with your Driverless AI address and login credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## install matplotlib\n",
    "# conda install -c conda-forge matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## install packages\n",
    "import sys\n",
    "!conda install --yes --prefix {sys.prefix} pandas\n",
    "!conda install --yes --prefix {sys.prefix} matplotlib\n",
    "!conda install --yes --prefix {sys.prefix} sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from h2oai_client import Client\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# address = 'http://ip_where_driverless_is_running:12345'\n",
    "address = 'http://18.140.223.189:12345'\n",
    "\n",
    "username = 'h2oai'\n",
    "## check new one\n",
    "password = 'h2oai'\n",
    "\n",
    "h2oai = Client(address = address, username = username, password = password)\n",
    "\n",
    "# make sure to use the same user name and password when signing in through the GUI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Datasets\n",
    "Upload training and testing datasets from the Driverless AI /data folder.\n",
    "\n",
    "You can provide a training, validation, and testing dataset for an experiment. The validation and testing dataset are optional. In this example, we will provide only training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## split data for modelling\n",
    "\n",
    "CC = pd.read_csv('./data/CreditCard.csv')\n",
    "train_cc, test_cc = model_selection.train_test_split(cc, test_size=0.2, random_state=2018)\n",
    "train_cc.to_csv(\"CreditCard-train.csv\", index=False)\n",
    "test_cc.to_csv(\"CreditCard-test.csv\", index=False)\n",
    "\n",
    "## load data\n",
    "\n",
    "train_path = '/data/CreditCard-train.csv'\n",
    "test_path = '/data/CreditCard-test.csv'\n",
    "\n",
    "train = h2oai.create_dataset_sync(train_path)\n",
    "test = h2oai.create_dataset_sync(test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Experiment Parameters\n",
    "We will now set the parameters of our experiment. Some of the parameters include:\n",
    "\n",
    "Target Column: The column we are trying to predict.\n",
    "\n",
    "Dropped Columns: The columns we do not want to use as predictors such as ID columns, columns with data leakage, etc.\n",
    "\n",
    "Weight Column: The column that indicates the per row observation weights. If None, each row will have an observation weight of 1.\n",
    "\n",
    "Fold Column: The column that indicates the fold. If None, the folds will be determined by Driverless AI.\n",
    "\n",
    "Is Time Series: Whether or not the experiment is a time-series use case.\n",
    "\n",
    "For information on the experiment settings, refer to the Experiment Settings.\n",
    "\n",
    "For this example, we will be predicting ``default payment next month``. The parameters that control the experiment process are: accuracy, time, and interpretability. We can use the get_experiment_preview_sync function to get a sense of what will happen during the experiment.\n",
    "\n",
    "We will start out by seeing what the experiment will look like with accuracy, time, and interpretability all set to 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "target=\"default payment next month\"\n",
    "exp_preview = h2oai.get_experiment_preview_sync(dataset_key= train.key\n",
    "                                                , validset_key=''\n",
    "                                                , classification=True\n",
    "                                                , dropped_cols=[]\n",
    "                                                , target_col=target\n",
    "                                                , is_time_series=False\n",
    "                                                , enable_gpus=False\n",
    "                                                , accuracy=5, time=5, interpretability=5\n",
    "                                                , reproducible=True\n",
    "                                                , resumed_experiment_id=''\n",
    "                                                , time_col=''\n",
    "                                                , config_overrides=None)\n",
    "exp_preview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these settings, the Driverless AI experiment will train about 124 models: \n",
    "* 16 for model and feature tuning\n",
    "* 104 for feature evolution\n",
    "* 4 for the final pipeline\n",
    "\n",
    "When we start the experiment, we can either: \n",
    "\n",
    "* specify parameters\n",
    "* use Driverless AI to suggest parameters\n",
    "\n",
    "Driverless AI can suggest the parameters based on the dataset and target column.  Below we will use the **`get_experiment_tuning_suggestion`** to see what settings Driverless AI suggests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let Driverless suggest parameters for experiment\n",
    "params = h2oai.get_experiment_tuning_suggestion(dataset_key = train.key, target_col = target, \n",
    "                                                is_classification = True, is_time_series = False,\n",
    "                                                config_overrides = None, cols_to_drop=[])\n",
    "\n",
    "params.dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Driverless AI has found that the best parameters are to set **`accuracy = 5`**, **`time = 4`**, **`interpretability = 6`**. It has selected **`AUC`** as the scorer (this is the default scorer for binomial problems)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch Experiment: Feature Engineering + Final Model Training\n",
    "\n",
    "Launch the experiment using the parameters that Driverless AI suggested along with the testset, scorer, and seed that were added. We can launch the experiment with the suggested parameters or create our own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = h2oai.start_experiment_sync(dataset_key=train.key,\n",
    "                                         testset_key = test.key,\n",
    "                                         target_col=target,\n",
    "                                         is_classification=True,\n",
    "                                         accuracy=5,\n",
    "                                         time=4,\n",
    "                                         interpretability=6,\n",
    "                                         scorer=\"AUC\",\n",
    "                                         enable_gpus=True,\n",
    "                                         seed=1234,\n",
    "                                         cols_to_drop=['ID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine Experiment\n",
    "\n",
    "View the final model score for the validation and test datasets. When feature engineering is complete, an ensemble model can be built depending on the accuracy setting. The experiment object also contains the score on the validation and test data for this ensemble model.  In this case, the validation score is the score on the training cross-validation predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Final Model Score on Validation Data: \" + str(round(experiment.valid_score, 3)))\n",
    "print(\"Final Model Score on Test Data: \" + str(round(experiment.test_score, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The experiment object also contains the scores calculated for each iteration on bootstrapped samples on the validation data.\n",
    "\n",
    "This information is saved in the experiment object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build an Experiment in Web UI and Access Through Python\n",
    "\n",
    "It is also possible to use the Python API to examine an experiment that was started through the Web UI using the experiment key.\n",
    "\n",
    "You can get a pointer to the experiment by referencing the experiment key in the Web UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of experiments\n",
    "experiment_list = list(map(lambda x: x.key, h2oai.list_models(offset=0, limit=100).models))\n",
    "experiment_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get pointer to experiment\n",
    "experiment = h2oai.get_model_job(experiment_list[0]).entity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
